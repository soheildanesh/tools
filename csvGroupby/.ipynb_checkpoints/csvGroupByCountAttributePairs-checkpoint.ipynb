{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# prupose of code here is to see how variable our vendor predictions are, baiscally it is a group by vendor_name, final_vendro_pred\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "#this file seems to have only one prediction per vendor:\n",
    "#inputFileName = \"/home/s.danesh.bahreini/projects/SpendCategorization/invoice_items_MRO_3.8.17.scores.20170308194000.csv\"\n",
    "\n",
    "#test file with multiple predicitons per vendors (for vend2 and vend3)\n",
    "inputFileName = \"/home/s.danesh.bahreini/myUtilities/csvGroupby/testdata/oneVendorMultiplePredictionsTest.csv\"\n",
    "\n",
    "\n",
    "attributeColName = \"VENDOR_NAME\"\n",
    "predictionColName = 'FINAL_VENDOR_PRED'\n",
    "\n",
    "def groupBy(inputFileName, attributeColName, predictionColName, maxRowsToRead = -1):\n",
    "    maxRowsToRead = -1 #set to -1 to read whole file\n",
    "    rowsRead = 0\n",
    "    attributePredictionsDict = {}\n",
    "\n",
    "    attributeValueCounts = {} #this is just for observation, to see how many times each vendor occures in the file - ignoring predictions for now\n",
    "\n",
    "\n",
    "    with open(inputFileName, 'rb') as csvfile:\n",
    "\n",
    "        #inputCsv = csv.reader(csvfile, delimiter=',', quotechar='\"') #read csv rows by index as opposed to column name - maybe useful for headerless csv files\n",
    "        csvReader = csv.DictReader(csvfile, delimiter=',', quotechar='\"')\n",
    "        for row in csvReader:\n",
    "            if(maxRowsToRead < 0 or rowsRead < maxRowsToRead):\n",
    "                attributeValue = row[attributeColName]\n",
    "\n",
    "                if(attributeValue not in attributeValueCounts):\n",
    "                    attributeValueCounts[attributeValue] = 1\n",
    "                else:\n",
    "                    attributeValueCounts[attributeValue] += 1\n",
    "\n",
    "\n",
    "\n",
    "                predictedValue = row[predictionColName]\n",
    "                #print(\"attibute = \"+ attributeValue + \", predicted value = \" +predictedValue)\n",
    "                rowsRead += 1\n",
    "\n",
    "                #update the number fof times in the dict where this attributeValue is mapped to this predictedValue\n",
    "                if attributeValue not in attributePredictionsDict:\n",
    "                    attributePredictionsDict[attributeValue] = {}\n",
    "                    attributePredictionsDict[attributeValue][predictedValue] = 0\n",
    "                if predictedValue not in attributePredictionsDict[attributeValue]:\n",
    "                    attributePredictionsDict[attributeValue][predictedValue] = 0\n",
    "                    \n",
    "                attributePredictionsDict[attributeValue][predictedValue] += 1\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    #todo take out of main execution later on \n",
    "    #this is just to see how many times each attribute value occurs\n",
    "    attributeValueCountsFileName = \"/home/s.danesh.bahreini/projects/SpendCategorization/invoice_items_MRO_3.8.17.scores.20170308194000.csv_attributeValueCounts.txt\"\n",
    "    attributeValueCountsFile = open(attributeValueCountsFileName, 'w')\n",
    "    for attributeValue in attributeValueCounts:\n",
    "        if(attributeValueCounts[attributeValue] > 1): #print only attribute values seen more than once\n",
    "            attributeValueCountsFile.write(attributeValue+\":\"+str(attributeValueCounts[attributeValue]))\n",
    "    attributeValueCountsFile.close()\n",
    "\n",
    "    #outputFileName = \"/home/s.danesh.bahreini/projects/SpendCategorization/invoice_items_MRO_3.8.17.scores.20170308194000.csv_entropyCalculator.txt\"\n",
    "    outputFileName = inputFileName+\"_grouped_\"+attributeColName+\"_by_\"+predictionColName+\".txt\"\n",
    "    indent = \"   \"\n",
    "    outputFile = open(outputFileName, 'w')\n",
    "    for attributeValue in attributePredictionsDict:\n",
    "        print(\"\\n\\n\")\n",
    "        #get all predicted values for this attribute value and sort them by frequency\n",
    "        predictedValueCountTuples=[]\n",
    "        dictOfPredictedValuesAndCountsForThisAttributeValue = attributePredictionsDict[attributeValue]\n",
    "\n",
    "        #first put them all in an array\n",
    "        for predictedValue in dictOfPredictedValuesAndCountsForThisAttributeValue:\n",
    "            count = dictOfPredictedValuesAndCountsForThisAttributeValue[predictedValue] #number of times this prediction value was made for this attribute value\n",
    "            predictedValueCountTuples.append((predictedValue, count))\n",
    "\n",
    "        #now sort predicted values by count\n",
    "        predictedValuesCountsSortedByCount = sorted(predictedValueCountTuples, key=lambda predictedValueCountTuple: predictedValueCountTuple[1], reverse=True)\n",
    "\n",
    "        outputFile.write(attributeValue+\"\\n\")\n",
    "        for valueCount in predictedValuesCountsSortedByCount:\n",
    "            outputFile.write(indent+valueCount[0]+\":\"+str(valueCount[1])+\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    outputFile.close()\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groupBy(inputFileName, attributeColName, predictionColName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    #outputFileName = \"/home/s.danesh.bahreini/projects/SpendCategorization/invoice_items_MRO_3.8.17.scores.20170308194000.csv_entropyCalculator.txt\"\n",
    "    outputFileName = inputFileName+\"grouped.txt\"\n",
    "    indent = \"   \"\n",
    "    outputFile = open(outputFileName, 'w')\n",
    "    for attributeValue in attributePredictionsDict:\n",
    "        print(\"\\n\\n\")\n",
    "        #get all predicted values for this attribute value and sort them by frequency\n",
    "        predictedValueCountTuples=[]\n",
    "        dictOfPredictedValuesAndCountsForThisAttributeValue = attributePredictionsDict[attributeValue]\n",
    "\n",
    "        #first put them all in an array\n",
    "        for predictedValue in dictOfPredictedValuesAndCountsForThisAttributeValue:\n",
    "            count = dictOfPredictedValuesAndCountsForThisAttributeValue[predictedValue] #number of times this prediction value was made for this attribute value\n",
    "            predictedValueCountTuples.append((predictedValue, count))\n",
    "\n",
    "        #now sort predicted values by count\n",
    "        predictedValuesCountsSortedByCount = sorted(predictedValueCountTuples, key=lambda predictedValueCountTuple: predictedValueCountTuple[1], reverse=True)\n",
    "\n",
    "        outputFile.write(attributeValue+\"\\n\")\n",
    "        for valueCount in predictedValuesCountsSortedByCount:\n",
    "            outputFile.write(indent+valueCount[0]+\":\"+str(valueCount[1])+\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    outputFile.close()   \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    #outputFile.write(attributeValue+\"\\n\") todo delete\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
